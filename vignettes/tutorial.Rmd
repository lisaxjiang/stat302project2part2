---
title: "Project 2: stat302project2part2 Tutorial"
author: "Lisa Jiang"
date: "12/16/2020"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{stat302project2part2 Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Set up package:
```{r install, eval = FALSE, results='hide'}
devtools::install_github("lisaxjiang/stat302project2part2")
```

Install packages and data:
```{r setup, results='hide'}
require(stat302project2)
library(stats)
library(dplyr, warn.conflicts = FALSE)
library(magrittr)
library(randomForest)
library(class)
library(ggplot2)
library(kableExtra)
library(tibble)
data("my_gapminder")
my_gapminder
data("my_penguins")
my_penguins <- na.omit(my_penguins)
```


# Part 2. Data Analysis Project Pipeline (15 points)

## Instructions

For this portion of Project 2, you are being asked to set up a GitHub repository demonstrating your ability to set up a systematic data analysis project workflow.
For this part, we are pretending we don't have a package and using code and analyses you have already generated for Part 1.

Your analysis should be contained on a GitHub repository and include:

* A `.Rproj` file with the name of the project.
* A `Data` subfolder with the raw, unprocessed data.
  * Within `Data`, save the `my_gapminder` and `my_penguins` data as a raw `.csv`. 
* A `Code` subfolder with code to be loaded by your analysis files.
  * Include `my_rf_cv.R` from your package in Part 1. You can include it exactly as it appears in your package, including documentation. Good `roxygen2` style documentation is not limited to packages!
* An `Analysis` subfolder.
  * Include a `.Rmd` file. This file can, for the most part, be a copy of part 5 from your package vignette. **However**, this R Markdown document must
    * load data directly from the `Data` subfolder,
    * use `source()` to source code directly from from the `Code` subfolder (your `.Rmd` should **not** include code generating the function `my_rf_cv`, it should load that function from your script!),
    * use `ggsave()` to save all your figures within your analysis scripts (remember, your relative path from files in `Analysis` will look like `"../Output/Figures"`).
    * use `saveRDS()` and `write_csv()` to save your table of summary statistics and your simulation results, respectively (see `Results` description).
* A `Output` subfolder with:
  * A `Figures` sub-subfolder with all the figures you generated in `Analysis`
  * A `Results` sub-subfolder that contains (a) your table of 8 summary statistics saved as a `.rds` file and (b) a `.csv` with your 90 simulated results with 3 columns for each value of $k$ and 30 rows for each simulation.
* A `.gitignore` file
  * Include `.Rproj.user` and `.Rhistory`

### Details

* Your data analysis project must be hosted on GitHub as a public repository. You are free to make the repository private after the course concludes.
* Your submission for this portion of the project will be a single link to your GitHub repository.
* Test whether your pipeline works. When you knit the `.Rmd` in your `Analysis` folder, it should re-load the `Data` and `Code` files and re-generate all the results in `Output`.
If your results in `Output` aren't systematically re-generated when you run your Analysis, something in your pipeline is broken!

